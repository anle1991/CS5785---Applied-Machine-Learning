{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) About the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cuisine/train.json\", \"r\") as file:\n",
    "    train_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, cuisine, ingredients = [], [], []\n",
    "for line in train_data:\n",
    "    ids.append(line[\"id\"])\n",
    "    cuisine.append(line[\"cuisine\"])\n",
    "    ingredients.extend(line[\"ingredients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set sample size:  39774\n",
      "Cuisine:  20\n",
      "Ingredient:  6714\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set sample size: \", len(ids))\n",
    "print(\"Cuisine: \", len(set(cuisine)))\n",
    "print(\"Ingredient: \", len(set(ingredients)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ingredient_index to map name to index\n",
    "ingredient_i = dict()\n",
    "i = 0;\n",
    "\n",
    "for ingredient in set(ingredients):\n",
    "    ingredient_i[ingredient] = i\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'southern_us',\n",
       " 'id': 25693,\n",
       " 'ingredients': ['plain flour',\n",
       "  'ground pepper',\n",
       "  'salt',\n",
       "  'tomatoes',\n",
       "  'ground black pepper',\n",
       "  'thyme',\n",
       "  'eggs',\n",
       "  'green tomatoes',\n",
       "  'yellow corn meal',\n",
       "  'milk',\n",
       "  'vegetable oil']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6714)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_arr = []\n",
    "ingredient_count = len(ingredient_i)\n",
    "\n",
    "# Use index map to set 1\n",
    "for line in train_data:\n",
    "    ing_arr = [0] * ingredient_count # Create 0 array\n",
    "    for i in line[\"ingredients\"]:\n",
    "        ing_arr[ingredient_i[i]] = 1\n",
    "    train_data_arr.append(ing_arr)\n",
    "train_data_arr = np.array(train_data_arr, dtype=int)\n",
    "train_label_arr = np.array(cuisine, dtype=str)\n",
    "\n",
    "train_data_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 6714)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"cuisine/test.json\", \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "test_data_arr = []\n",
    "test_id = []\n",
    "    \n",
    "for line in test_data:\n",
    "    test_id.append(line[\"id\"])\n",
    "    ing_arr = [0] * ingredient_count # Create 0 array\n",
    "    for i in line[\"ingredients\"]:\n",
    "        if i in ingredient_i:\n",
    "            ing_arr[ingredient_i[i]] = 1\n",
    "    test_data_arr.append(ing_arr)\n",
    "test_data_arr = np.array(test_data_arr, dtype=int)\n",
    "test_id = np.array(test_id, dtype=int)\n",
    "\n",
    "test_data_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Naive Bayes f) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB:  0.379846130638\n",
      "BernoulliNB:  0.683536983959\n",
      "LogisticRegression:  0.775556896465\n"
     ]
    }
   ],
   "source": [
    "fold = 3\n",
    "kf = KFold(len(train_data_arr), n_folds=fold)\n",
    "\n",
    "clf_B = BernoulliNB()\n",
    "clf_G = GaussianNB()\n",
    "clf_L = LogisticRegression()\n",
    "\n",
    "avg_B, avg_G, avg_L = 0, 0, 0\n",
    "for train_i, test_i in kf:\n",
    "    data_train = train_data_arr[train_i]\n",
    "    data_test = train_data_arr[test_i]\n",
    "    label_train = train_label_arr[train_i]\n",
    "    label_test = train_label_arr[test_i]\n",
    "    \n",
    "    clf_B.fit(data_train, label_train)\n",
    "    clf_G.fit(data_train, label_train)\n",
    "    clf_L.fit(data_train, label_train)\n",
    "    \n",
    "    avg_B += clf_B.score(data_test, label_test) / fold\n",
    "    avg_G += clf_G.score(data_test, label_test) / fold\n",
    "    avg_L += clf_L.score(data_test, label_test) / fold\n",
    "\n",
    "print(\"GaussianNB: \", avg_G)\n",
    "print(\"BernoulliNB: \", avg_B)\n",
    "print(\"LogisticRegression: \", avg_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) BernoulliNB scores 0.68 meanwhile GaussianNB scores 0.38. BernoulliNB performs better since the data (ingredients) describes whether an ingredient is present or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_L.fit(train_data_arr, train_label_arr)\n",
    "pred_L = clf_L.predict(test_data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(test_id, columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"cuisine\"] = pred_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cuisine\n",
       "0  18009       british\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"kaggle_cuisine.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
